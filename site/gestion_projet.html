<!DOCTYPE html>
<html lang="fr">
	<head>
    	<title>SAE23 - Gestion de projet</title>
    	<meta charset="utf-8">
    	<meta name="viewport" content="width=device-width, initial-scale=1" />
    	<meta name="author" content="CTL" />
    	<meta name="description" content="Gestion de projet" />
    	<meta name="keywords" content="HTML, CSS" />
    	<link rel="preconnect" href="https://fonts.googleapis.com">
    	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    	<link href="https://fonts.googleapis.com/css2?family=Lexend:wght@100;200;300&display=swap" rel="stylesheet">
    	<link rel="stylesheet" type="text/css" href="./styles/style.css" media="screen" />
	</head>

	<!-- Project Management page -->

	<body>

		<header>
			<h1>Gestion de projet</h1>
		</header>

		<p>
			Dans le cadre de la SAE 23, nous avons du mobiliser nos compétences en informatique pour concevoir deux solutions de traitement de données. Nous devions choisir de traiter une seule grandeur et au minimum quatre capteurs répartis sur deux bâtiments ; nous avons choisi de traiter les données des capteurs de CO2 situés dans les salles B002, B105, E003, et E105, en laissant la possibilité à l'administrateur de rajouter des capteurs à traiter.
		</p>
		<br/>
		<ol>
			<li>
				<p>
					La première solution de traitement de données implique l'utilisation de conteneurs qui isolent les différents outils utiliser. Le premier outil est NodeRed, pour récupérer et traiter les données émises par les capteurs de l'IUT. NodeRed est un outil de développement pour la programmation visuelle, c'est-à-dire qu'il permet de traiter des informations en programmant à l'aide d'une interface graphique, sans code.
				<p>
					Nous avons programmé cet outil pour qu'il récupère les données en CO2 des capteurs qui nous intéressaient, qu'il les présente sous la forme de graphes, et enfin qu'il les stocke dans une base de données InfluxDB, qui est un système de base de données en temps réel, c'est-à-dire que chaque mesure entrée dans la base de données est automatiquement horodatée. Cela est donc très utile pour traiter les données de capteurs de CO2 ou encore de température, puisque ce sont des grandeurs qui évoluent beaucoup dans le temps.
				</p>
				<p>
					Enfin, cette solution implique également l'utilisation de Grafana, qui est un logiciel qui permet de visualiser les données stockées dans une base de données via des graphiques.
				</p>
				<p>
					Cette première solution est donc une solution sans codage et qui implique l'utilisation de conteneurs ; elle offre de belles visualisations des données émises par les capteurs.
				</p>
			</li>
			<br/>
			<li>
				<p>
					La deuxième solution implique la réalisation de scripts pour récupérer les données des capteurs et les envoyer sur une base de données MySQL. Nous avons choisi de réaliser ces scripts en Bash.
				</p>
				<p>
					Il nous a également fallu réaliser le site web dynamique que voici afin de présenter les résultats de cette solution, avec une partie Consultation qui permet de visualiser sous forme de tableau les dernières données envoyées par les capteurs et stockées dans la base de données, une partie Administration qui permet de modifier la base de données en y ajoutant ou supprimant des bâtiments, des salles, ou encore des capteurs, et enfin une partie Gestionnaires qui permet au gestionnaire de chaque bâtiment de visualiser les données envoyées par les capteurs de son bâtiment seulement. Cette seconde solution est une solution pas-à-pas, qui implique beaucoup plus de codage que la première.
				</p>
			</li>
		</ol>

		<br/>

		<section>
			<h2>Répartition du travail</h2>
			<p>
				Nous nous sommes répartis les différentes tâches en prenant en compte nos préférences mais aussi la charge de travail que chaque tâche représentait.
			</p>
			<p>
				Ainsi, Chloé FOURMAN s'est chargée de la conception de la base de données et de la partie Administration du site web, ainsi que des pages d'accueil et de mentions légales.
			</p>
			<p>
				Lola SCHULER s'est chargée des scripts Bash et de la partie Gestionnaires du site web, ainsi que de la page Gestion de projet.
			</p>
			<p>
				Quant à Timothée SENDRA, il s'est chargé des flow et dashboards Nodered et Grafana, ainsi que de la page Consultation du site web.
			</p>
			<br/>
			<p>
				Après avoir clairement défini les tâches à accomplir, nous avons pu nous projeter dans le temps pour prévoir quelle tâche serait faite à quel moment. A cette fin, nous avons réalisé un diagramme de Gantt qui nous a aidé à visualiser le calendrier des tâches :
			</p>

			<figure class="calendrier">
				<a href="./images/gantt_prev.jpg" download>
				<img src="./images/gantt_prev.jpg" alt="Gantt prévisionnel" title="Gantt prévisionnel"/> 
				</a>
				<figcaption>Gantt prévisionnel</figcaption>
			</figure>

			<p>
				Cependant, au fur et à mesure du temps, nous nous sommes un peu écartés du calendrier : certaines tâches ont pris plus de temps que ce que nous avions prévu, et d'autres moins. Nous avons consigné ces changements dans un diagramme de Gantt final.
			</p>

			<figure class="calendrier">
				<a href="./images/gantt_final.jpg" download>
				<img src="./images/gantt_final.jpg" alt="Gantt final" title="Gantt final"/>
				</a>
				<figcaption>Gantt final</figcaption>
			</figure>

			<p>
				Nous pouvons donc observer que la partie déploiement et configuration des conteneurs a pris légèrement plus longtemps que prévu, tout comme la partie écriture et automatisation des scripts, qui a pris presque deux semaines au lieu d'une. Cela s'explique en partie par le changement d'organisation des scripts décidé par Lola SCHULER, qui, dans un souci d'optimisation et d'adaptabilité, a décidé d'organiser différemment ses scripts qu'elle venait de finir, ce qui a engendré du travail supplémentaire.
			</p>
			<p>
				La partie création du site web dynamique, quant à elle, a pris autant de temps que prévu, c'est-à-dire deux semaines, sans que le calendrier soit particulièrement suivi pour autant. En effet, nous nous sommes rendus compte à l'écriture du site web que le plus urgent semblait en réalité non pas être la page Gestion de Projet, mais plutôt les parties Administrateur et Gestionnaires du site web qui, étant bien plus compliquées, allaient demander beaucoup plus de temps. Et effectivement, la partie Administration du site web, pour laquelle nous avions prévu une petite semaine de travail, en a finalement demandé presque deux. Cela est dû à la complexité de cette partie, qui demande une bonne maîtrise du code PHP.
			</p>
			<p>
				Enfin, l'écriture de la page Gestion de Projet et du CSS pour mettre en forme le site web a été reléguée à la toute fin du projet, comme elle nous semblait secondaire par rapport aux autres tâches qu'il nous restait encore à réaliser.
			</p>

		</section>

		<br/>

		<section>
			<h2>Outils collaboratifs utilisés</h2>
			<p>
				Pour pouvoir travailler efficacement nous nous sommes aidés de plusieurs outils collaboratifs qui nous ont aidé à nous organiser ainsi qu'à mettre en commun notre travail :
			</p>
			<ul id="gauche">
				<li class="outils">
					<p>Github, afin de partager notre travail et de garder trace du travail effectué tout au long du projet. Cet outil nous a permis de conserver un accès aux différentes versions de nos fichiers, pour pouvoir y retourner si le besoin s'en faisait sentir. Pour consulter notre Repository, <a href="https://github.com/LolaSchuler/SAE23" target="_blank">veuillez cliquer ici !</a></p>
					<figure class="droite">
						<a href="./images/github.jpg" download>	
						<img src="./images/github.jpg" alt="Interface GitHub" title="Interface GitHub"/>
						</a>
						<figcaption>Interface Github</figcaption>
					</figure>
				</li>
				<li class="outils">
					<p>Google Drive, afin de se partager et d'organiser les fichiers de brouillon ou de préparation du projet</p>
					<figure class="droite">
						<a href="./images/drive.jpg" download>	
						<img src="./images/drive.jpg" alt="Interface Google Drive" title="Interface Google Drive"/>
						</a>
						<figcaption>Interface Google Drive</figcaption>
					</figure>
				</li>
				<li class="outils">
					<p>Trello, qui nous a permis de visualiser facilement les tâches faites et celles à faire</p>
					<figure class="droite">
						<a href="./images/trello.jpg" download>	
						<img src="./images/trello.jpg" alt="Interface Trello" title="Interface Trello"/>
						</a>
						<figcaption>Interface Trello</figcaption>
					</figure>
				</li>
			</ul>

		</section>

		<br/>

		<section>
			<h2>Synthèses personnelles des membres du groupe</h2>

			<br/>

			<article>
				<h3>Chloé FOURMAN</h3>
				<p>
					Lors de cette SAE, j’ai choisi de principalement m’occuper de la partie gestion de base de données. Ainsi, j’ai créé et initialisé la base de données sur PHPMyAdmin et je me suis occupée des pages “Administration”.
				</p>
				<p>
					Dans un premier temps, j’ai dû commencer par créer une nouvelle base de données (“sae23”) ainsi qu’un nouvel utilisateur (dans notre cas “CTL” pour Chloé Timothée Lola) associé à la base de données afin de pouvoir créer des tables par la suite.
				</p>
				<p>
					Une fois les tables initialisées sur PHPMyAdmin, j’ai pu commencer à écrire les pages HTML et PHP d’Administration. 
				</p>
				<p>
					Pour ce faire, j’ai choisi de commencer par initialiser une session grâce à un formulaire ayant pour but de vérifier l’identité de l’utilisateur grâce à un nom d’utilisateur ainsi qu’un mot de passe entrés dans le formulaire qui seront comparés par la suite avec la table “Administration” (contenant les identifiants corrects à utiliser). En effet, grâce à cela, seuls ceux qui ont connaissance de ces identifiants peuvent avoir accès aux pages de gestion de la base de données. En cas de mauvais identifiants entrés, ou bien d’une absence d’information, l’utilisateur sera redirigé vers une page d’erreur de login que nous avons décidé d’utiliser de façon commune à tout le site Web afin d’en simplifier l’arborescence. Ainsi, deux liens principaux apparaissent sur cette page : le retour à l’authentification gestionnaire et le retour à l’authentification administrateur.
				</p>
				<p>
					En ce qui concerne les pages suivantes, soit celles uniquement accessibles après authentification, j’ai choisi de ne pas faire tous les formulaires sur une seule page mais plutôt de pousser l’utilisateur à suivre un chemin où il choisit ce qu’il veut faire petit à petit. Ainsi, il commence par choisir la table à modifier avant de choisir ce qu’il compte y faire (ajout ou suppression de ligne) et d’être redirigé vers une page qui informe d’une erreur d’exécution (que nous avons en commun entre toutes les pages du site) ou bien qui valide la bonne exécution de la requête et renvoie la table modifiée par la suite.

				</p>
				<p>
					De plus, j’ai choisi de définir plusieurs valeurs communes notamment pour pouvoir conserver le nom de la table modifiée, les lignes à supprimer ou bien à ajouter, …
				</p>
				<p>
					Pour ce faire, j’ai commencé par utiliser des méthodes POST, mais je me suis vite retrouvée limitée puisqu’il fallait systématiquement des formulaires avec des variables cachées afin de pouvoir transférer les données à la page suivante. Ainsi, j’ai commencé à utiliser des variables contenues dans la session, ce qui était bien plus simple.
				</p>
				<p>
					Cependant, j’ai choisi de conserver les deux méthodes réparties sur les pages afin de montrer que les deux peuvent fonctionner ; l’une est juste plus pratique que l’autre.
				</p>
				<p>
					Pendant l’écriture de ces pages, j’ai décidé de faire la page d’accueil afin de simplifier la navigation sur le site Web. En effet, au début nous devions utiliser les URL précises afin de pouvoir vérifier nos codes, comme il n’y avait aucun lien pour accéder à la première page de nos sections respectives.
				</p>
				<p>
					De plus, j’ai aussi choisi de faire une brève pause pendant l’écriture de mes pages afin de me consacrer à la génération d’une page sur les mentions légales.
				</p>
			</article>

			<br/>

			<article>
				<h3>Timothée SENDRA</h3>
				<p>
					Au cours de cette SAE, j’ai pu travailler sur plusieurs sujets. J’ai été chargé de créer des conteneurs Docker, tâche que j’ai pu accomplir assez facilement grâce au TP formatif qui était très utile.
				</p>
				<p>
					J’ai donc créé 4 conteneurs : Mosquitto, Node-RED, Grafana et InfluxDB. Chacun de ces conteneurs a un nom associé à ses fonctions. Mosquitto : MosquittoRT, Node-RED : NodeRedRT, InfluxDB : InfluxDBRT, Grafana : GrafanaRT. Néanmoins, avant de mettre en place les conteneurs, j’ai configuré le serveur XAMPP que j’ai sécurisé en utilisant un mot de passe différent pour chaque processus, comme phpMyAdmin.
				</p>
				<p>
					Suite à cela, j’ai pu créer le flow Node-RED dans lequel j’ai récupéré des données sur le broker Mosquitto pour les traiter et extraire uniquement les valeurs de CO2 qui se trouvaient dans un tableau à deux cases. J’ai donc dû écrire un script dans un bloc “fonction” pour trier les différentes données du capteur et ne récupérer que la valeur de CO2 que nous voulions traiter. Par la suite, mon travail a consisté à utiliser InfluxDB pour stocker les données récupérées dans le flow Node-RED dans la base de données InfluxDB.
				</p>
				<p>
					J’ai aussi pris en charge Grafana, tâche qui devait initialement être réalisée par Lola SCHULER, mais qui a rencontré un problème avec sa VM et n’a donc pas pu le faire. Le Grafana avait pour but de créer un affichage similaire à celui que nous avions sur le dashboard Node-RED (sous forme de jauge) mais en récupérant les informations depuis la base de données InfluxDB.
				</p>
				<p>
					Enfin, j’ai réalisé une des pages du site web : la page de consultation, qui avait pour objectif d'afficher les dernières mesures de chaque capteur traitées de façon horodatée.

				</p>
			</article>

			<br/>

			<article>
				<h3>Lola SCHULER</h3>
				<p>
					Je me suis occupée en premier lieu des scripts en Bash pour récupérer et traiter les données provenant des capteurs et mises à disposition sur le bus MQTT de l'IUT.
				</p>
				<p>
					J'ai tout d'abord conçu un script de récupération des données en m'inspirant du script que j'avais écrit pour la SAE15, à la fin du premier semestre. Ensuite, j'ai écris un script d'insertion des données dans la base de données MySQL. Après avoir validé séparément le fonctionnement de ces deux scripts avec des capteurs et des valeurs aléatoires, j'ai appliqué leur fonctionnement aux quatre capteurs que nous avons choisi.
				</p>
				<br/>
				<p>
					Mon premier choix a été de réaliser quatre scripts différents, un pour chaque capteur étudié. J'avais un script qui lançait tous les autres scripts tour à tour, comme je l'avais fait pour la SAE15. Mon premier script récupérait donc de la base de données MySQL la liste des capteurs dans la table Capteur, et la stockait dans un fichier texte.
				</p>
				<p>
					Le script suivant (qui s'appelait e003_data_extraction) retirait de ce fichier texte le nom du capteur de la salle E003, récupérait du broker MQTT le message de ce capteur et traitait ce message pour n'en récupérer que la valeur du CO2, avant d'appeler le script d'insertion des données en passant la valeur générée par le capteur et le nom du capteur en argument. Les trois autres salles que nous avons choisi avaient chacune leur script, qui fonctionnaient de la même façon.
				</p>
				<p>
					Le dernier script, celui d'insertion des données, exécutait simplement une requête SQL pour insérer dans la base de données une nouvelle ligne dans la table Mesure, en fonction de la valeur des arguments.
				</p>
				<br/>
				<p>
					J'ai finalement trouvé cette méthode très peu efficace, puisqu'elle nécessitait un grand nombre de fichiers et s'adaptait très mal : en effet, la partie Administration du site web est censée permettre à un utilisateur de rajouter un capteur de son choix ; or, il faut dans ce cas que les mesures données par le nouveau capteur s'affichent dans la table Mesure. J'ai donc totalement changé l'organisation de mes scripts pour les optimiser au mieux et améliorer leur adaptabilité.
				</p>
				<p>
					Ma nouvelle solution utilise beaucoup moins de fichiers : j'ai toujours un script dit "de lancement" pour récupérer la liste des capteurs dans la table Capteur de la base de données et la stocker dans un fichier texte, mais au lieu d'avoir quatre scripts (un par capteur) pour récupérer les valeurs générées par les capteurs, je n'ai plus que un script-type, qui s'adapte pour chaque capteur listé dans le fichier texte "capteurs" et envoie directement les données dans la base de données MySQL. Cette nouvelle solution s'adapte donc au nombre de capteurs listés dans la table "Capteur".
				</p>
				<p>
					Le script de lancement appelle dans une boucle "for" le script de récupération et traitement des données, autant de fois qu'il y a de lignes dans la liste des capteurs. J'ai décidé d'appeler à chaque fois le script de récupération et de traitement des données en arrière-plan, car puisqu'un capteur émet des mesures à une intervalle de 10 minutes, il était sinon possible à chaque itération de la boucle qu'il faille attendre 10 minutes pour récupérer une nouvelle mesure. Puisque la table Capteur comporte au départ 4 capteurs, cela symboliserait une attente éventuelle de 40 minutes pour que le script s'exécute en entier.
				</p>
				<p>
					Il était donc préférable d'exécuter les scripts de récupération et de traitement des données en arrière-plan, pour que ces scripts s'exécutent en même temps et que l'attente maximale soit réduite à 10 minutes.
				</p>
				<br/>
				<p>
					J'étais également chargée de la réalisation du dashboard Grafana. Seulement, après avoir récupéré une copie de la VM de Timothée SENDRA, qui s'était occupé du flow NodeRed et de la base de données InfluxDB, nous nous sommes rendus compte que la base de données InfluxDB ne se remplissait pas correctement sur ma VM. Après avoir tenté de corriger le problème le temps d'une séance de SAE, nous avons décidé de ne pas perdre plus de temps, et j'ai finalement également confié à Timothée SENDRA la réalisation du dashboard Grafana, puisque le flux NodeRed et la base de données InfluxDB fonctionnaient sur sa VM.
				</p>
				<br/>
				<p>
					Enfin, je me suis chargée de la partie Gestionnaires du site web. Pour la réaliser, je me suis inspirée du site SMI sur lequel nous avions travaillé en R209, ainsi que de la partie Administration du site web, que Chloé FOURMAN avait déjà bien avancée quand je me suis attaquée à la partie Gestionnaires.
				</p>
			</article>

		</section>

		<section>
			<h2>Problèmes rencontrés et solutions proposées</h2>

			<ol>
				<li>
					Nous avons rencontré un problème avec les conteneurs qui nous a obligé à changer notre répartition du travail. En effet, après avoir copié la VM de Timothée SENDRA (sur laquelle étaient installés les conteneurs InfluxDB et NodeRed) sur la machine de Lola SCHULER, nous avons rencontrés des problèmes avec le remplissage via le flux NodeRed de la base de données InfluxDB. Comme nous avions peur de manquer de temps avant le rendu des livrables 2 et 3 (les conteneurs), nous avons préféré re-répartir le travail : Lola SCHULER, qui était initialement chargée du conteneur Grafana, en a confié la réalisation à Timothée SENDRA, car les conteneurs fonctionnaient comme prévu sur sa VM à lui.
				</li>
				<br/>
				<li>
					Nous avons rencontré d'autres problèmes, plus divers avec les machines virtuelles. Nous avons décidé de tout d'abord créer une machine virtuelle sur laquelle Chloé FOURMAN a installé et configuré la base de données MySQL, puis nous avons fait des copies de cette VM afin que nous disposions tous d'une machine virtuelle viable. Divers problèmes en rapport avec les machines virtuelles se sont cependant posés tout au long du projet : l'une des trois machines virtuelles ne cessait de planter, le terminal d'une autre disparaissait si tôt qu'on bougeait la fenêtre, etc. Comme il s'agissait de problèmes difficilement corrigeables en peu de temps, nous avons tout simplement appris à faire avec.
				</li>
				<br/>
				<li>
					Enfin, au sein de la partie Gestionnaires du site web, Lola SCHULER a rencontré un problème en particulier ; elle a eu du mal à conserver la variable $username d'une page à l'autre de la partie Gestionnaires. La solution a été de simplement stocker la variable dans les données de session de l'utilisateur, ce qui permet de conserver les variables tout au long de la session.
				</li>
			</ol>
		</section>


		<section>
			<h2>Conclusion sur le degré de satisfaction du cahier des charges</h2>
			<p>
				Nous sommes satisfaits du travail accompli et estimons avoir rempli le cahier des charges, sans particulièrement le dépasser pour autant ; l'ensemble des solutions proposées fonctionnent.
			</p>
			<p> Concrètement, voici un récapitulatif du cahier des charges accompagné de ce que nous avons fait : </p>
			<table id="gestion_projet">
				<tr class="titre">
					<th> Cahier des charges </th> <th> Manque dans notre travail </th> <th> Accompli </th> 
				</tr>
				<tr>
					<td> "Mettre en place une chaîne de traitement via des conteneurs." </td> <td> ☐ </td> <td> ☑ </td> 
				</tr>
				<tr>
					<td> "Créer un dashboard Grafana complet." </td> <td> ☐ </td> <td> ☑ </td>
				</tr>
				<tr>
					<td> "Coder un site web dynamique sur un serveur lampp." </td> <td> ☐ </td> <td> ☑ </td> 
				</tr>
				<tr>
					<td> "Coder un script récupérant les données sur un bus MQTT <br />
					(langage au choix : bash, php, C, python,. . .)." </td>
					<td> ☐ </td> <td> ☑ </td> 
				</tr>
				<tr>
					<td> "Créer et gérer une base de données MySQL." </td> <td> ☐ </td> <td> ☑ </td>
				</tr>
				<tr>
					<td> "Automatiser la chaîne de traitement (scripts dans crontab)." </td> <td> ☐ </td> <td> ☑ </td>
				</tr>
			</table>
		
		</section>


    	<hr />
    
		<footer>
			<nav>
				<ul>
					<li><a href="index.php"> Retour à la page d'accueil </a></li>
					<li><a href="admin_formulaire.html"> Espace administrateur </a> (accès restreint) </li>
					<li><a href="gestion_authentification.html"> Espace gestionnaire </a> (accès restreint) </li>
					<li><a href="consultation.php"> Consultation des dernières valeurs </a></li>
					<li><a href="mentions.html"> Mentions légales </a></li>
				</ul>
			</nav>
    	</footer>

	</body>
</html>
